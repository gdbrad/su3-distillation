#!/bin/bash
# template for computing charm perambulators with chroma in binned srun instances 

#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1 
#SBATCH --partition=dc-gpu
#SBATCH --gpu-bind=none
#SBATCH --account=exotichadrons
#SBATCH -t 24:00:00
#SBATCH --gres=gpu:4

export OPENBLAS_NUM_THREADS=16
export OMP_NUM_THREADS=16

CODE_DIR=/p/scratch/exotichadrons/chroma-superb
myenv=$CODE_DIR/env-new-jureca-gpu.sh
formenv=$CODE_DIR/env_extra.sh
source $myenv 
source $formenv
chroma=$CODE_DIR/install/chroma-quda-qdp-jit-double-nd4-cmake-superbblas-cuda/bin/chroma

BASE_DIR={{ run_path }}
if [ ! -d "$BASE_DIR/res/log/perams_charm" ]; then
  mkdir -p "$BASE_DIR/res/log/perams_charm";
fi 
if [ ! -d "$BASE_DIR/res/out/perams_charm" ]; then
  mkdir -p "$BASE_DIR/res/out/perams_charm";
fi 

export OPTS=" -geom 1 1 1 1"

{% for cfg_id, device_id in cfg_ids_and_devices %}
log_{{ cfg_id }}=$BASE_DIR/res/log/perams_charm/perams_{{ cfg_id }}_numvecs-{{ num_vecs_perams }}.log
in_{{ cfg_id }}=$BASE_DIR/ini-24/cnfg{{ cfg_id }}/numvec{{ num_vecs_perams }}/peram_charm_mg_96_cfg{{ cfg_id }}.ini.xml
out_{{ cfg_id }}=$BASE_DIR/res/out/perams_charm/perams_{{ cfg_id }}_numvecs-{{ num_vecs_perams }}.out.xml
output_{{ cfg_id }}="$BASE_DIR/chroma_out/binned/perams_charm_{{ cfg_id }}_numvecs-{{ num_vecs_perams }}.out"

CUDA_VISIBLE_DEVICES={{ device_id }} srun --exclusive -n 1 --gres=gpu:1 -c 16 $chroma $OPTS -i $in_{{ cfg_id }} -o $out_{{ cfg_id }} -l $log_{{ cfg_id }} > $output_{{ cfg_id }} 2>&1 &
{% if not loop.last %}
sleep 20
{% endif %}
{% endfor %}
wait

